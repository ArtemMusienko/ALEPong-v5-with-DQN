## ALE/Pong-v5 with DQN

В данном коде используется такая среда обучения, как **ALE/Pong-v5**. 1.  Реализована нейросетевая архитектура на полносвязных слоях, определены классы  `NNModel`  и  `DQN`, реализующие предсказательную и целевую сети, буфер воспроизведения, ε-жадную стратегию, синхронизацию весов и шаг обучения, реализован цикл обучения агента с ε-жадной стратегией и постепенным уменьшением ε, а также график динамики награды по эпизодам.

В финальной части notebook приведён анализ поведения агента и вывод.

> Настоятельно рекомендую код запускать в **Google Colab** с
> использованием **графического ускорителя T4**!